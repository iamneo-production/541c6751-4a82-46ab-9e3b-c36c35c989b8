{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Data Pre-Processing"
      ],
      "metadata": {
        "id": "84ssVc8TEobj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Necessary Libraries"
      ],
      "metadata": {
        "id": "y4M52hHi4xg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "pEDLncHZAcK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instructions to use the file:\n",
        "#1. Collect the daily files for the weather data\n",
        "#2. Run the function daily_weather_cleanup for each of the 5 districts.\n",
        "#3. Run warangal_merge function to cleanup and merge the 5 files belong to the warangal district. {This is only applicable for warangal}"
      ],
      "metadata": {
        "id": "n_x662vDArh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def daily_weather_cleanup(district):\n",
        "  '''\n",
        "  Arguments: \n",
        "  district -> The name of the district\n",
        "\n",
        "  The function cleans the data in the appropriate directory. The function only works when the following data files are given.\n",
        "  1. 1x File of 2018 daily weather data.  [All 12 months of 2018]\n",
        "  2. 4x files of 2019 daily weather data. [Jan to Mar, Apr to Jun, Jul to Sep, Oct to Dec]\n",
        "  3. 4x files of 2020 daily weather data. [Jan to Mar, Apr to Jun, Jul to Sep, Oct to Dec]\n",
        "  4. 10x files of 2021 daily weather data. [Jan to Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec]\n",
        "  5. 9x files of 2022 daily weather data. [Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep]\n",
        "  '''\n",
        "  #2018 Cleanup Begins\n",
        "  data_2018_all = pd.read_csv('raw_data/2018_daily_complete_weather_data_0.csv')\n",
        "  data_2018_allwarangal = data_2018_all.loc[data_2018_all['district'] == city]\n",
        "  data_2018_allwarangal = data_2018_allwarangal.drop(columns=['row_id','mandal','location'])\n",
        "  data_2018_allwarangal['odate'] = pd.to_datetime(data_2018_allwarangal['odate'],format='%d/%m/%y')\n",
        "  data_2018_allwarangal = data_2018_allwarangal.groupby(['odate', 'district'], as_index=False, sort=True).agg('max')\n",
        "  data_2018_allwarangal.index = data_2018_allwarangal['odate']\n",
        "  data_2018_allwarangal = data_2018_allwarangal.drop(columns=['odate'])\n",
        "  #2018 Cleanup Ends------------------------------------------------------------------------------------------------\n",
        "\n",
        "  #2019 Cleanup Begins------------------------------------------------------------------------------------------------\n",
        "  data_2019_jan_to_mar = pd.read_csv('raw_data/January_to_March_2019.csv')\n",
        "  data_2019_apr_to_jun = pd.read_csv('raw_data/April_to_June_2019.csv')\n",
        "  data_2019_jul_to_sep = pd.read_csv('raw_data/July_to_Sept_2019.csv')\n",
        "  data_2019_oct_to_dec = pd.read_csv('raw_data/Oct_to_Dec_2019.csv')\n",
        "  data_2019_jan_to_mar = data_2019_jan_to_mar.loc[data_2019_jan_to_mar['District'] == district]\n",
        "  data_2019_jan_to_mar = data_2019_jan_to_mar.drop(columns=['Mandal'])\n",
        "  data_2019_jan_to_mar['Date'] = pd.to_datetime(data_2019_jan_to_mar['Date'],format='%Y/%m/%d')\n",
        "  data_2019_jan_to_mar = data_2019_jan_to_mar.groupby(['District', 'Date'], as_index=False).agg('max')\n",
        "  data_2019_jan_to_mar.index = data_2019_jan_to_mar['Date']\n",
        "  data_2019_jan_to_mar = data_2019_jan_to_mar.drop(columns=['Date'])\n",
        "\n",
        "  data_2019_apr_to_jun = data_2019_apr_to_jun.loc[data_2019_apr_to_jun['District'] == district]\n",
        "  data_2019_apr_to_jun = data_2019_apr_to_jun.drop(columns=['Mandal'])\n",
        "  data_2019_apr_to_jun['Date'] = pd.to_datetime(data_2019_apr_to_jun['Date'],format='%Y/%m/%d')\n",
        "  data_2019_apr_to_jun = data_2019_apr_to_jun.groupby(['District', 'Date'], as_index=False).agg('max')\n",
        "  data_2019_apr_to_jun.index = data_2019_apr_to_jun['Date']\n",
        "  data_2019_apr_to_jun = data_2019_apr_to_jun.drop(columns=['Date'])\n",
        "\n",
        "  data_2019_jul_to_sep = data_2019_jul_to_sep.loc[data_2019_jul_to_sep['District'] == district]\n",
        "  data_2019_jul_to_sep = data_2019_jul_to_sep.drop(columns=['Mandal'])\n",
        "  data_2019_jul_to_sep['Date'] = pd.to_datetime(data_2019_jul_to_sep['Date'],format='%Y/%m/%d')\n",
        "  data_2019_jul_to_sep = data_2019_jul_to_sep.groupby(['District', 'Date'], as_index=False).agg('max')\n",
        "  data_2019_jul_to_sep.index = data_2019_jul_to_sep['Date']\n",
        "  data_2019_jul_to_sep = data_2019_jul_to_sep.drop(columns=['Date'])\n",
        "\n",
        "  data_2019_oct_to_dec = data_2019_oct_to_dec.loc[data_2019_oct_to_dec['District'] == 'Karimnagar']\n",
        "  data_2019_oct_to_dec = data_2019_oct_to_dec.drop(columns=['Mandal', \"Unnamed: 0\"])\n",
        "  data_2019_oct_to_dec['Date'] = pd.to_datetime(data_2019_oct_to_dec['Date'],format='%Y/%m/%d')\n",
        "  data_2019_oct_to_dec = data_2019_oct_to_dec.groupby(['District', 'Date'], as_index=False).agg('max')\n",
        "  data_2019_oct_to_dec.index = data_2019_oct_to_dec['Date']\n",
        "  data_2019_oct_to_dec = data_2019_oct_to_dec.drop(columns=['Date'])\n",
        "  data_2019_allwarangal = pd.concat([data_2019_jan_to_mar, data_2019_apr_to_jun, data_2019_jul_to_sep, data_2019_oct_to_dec])\n",
        "  data_2019_allwarangal.columns = data_2018_allwarangal.columns\n",
        "  #2019 Cleanup Ends------------------------------------------------------------------------------------------------\n",
        "\n",
        "  #2020 Cleanup Begins------------------------------------------------------------------------------------------------\n",
        "  data_2020_jan_to_mar = pd.read_csv('raw_data/jaunary_march_2020.csv')\n",
        "  data_2020_apr_to_jun = pd.read_csv('raw_data/april_to_june.csv') \n",
        "  data_2020_jul_to_sep = pd.read_csv('raw_data/july_to_sept.csv')\n",
        "  data_2020_oct_to_dec = pd.read_csv('raw_data/October to December 2020.xlsx - data.csv')\n",
        "  data_2020_oct_to_dec = data_2020_oct_to_dec.drop(columns = [\"Dcode\",\"Mcode\"])\n",
        "  data_2020_oct_to_dec.drop([52285], axis=0, inplace=True)\n",
        "  data_2020_oct_to_dec['Humidity Min (%)'] = data_2020_oct_to_dec['Humidity Min (%)'].astype(float)\n",
        "  data_2020_jul_to_sep = data_2020_jul_to_sep.drop(columns = [\"dmcode\"])\n",
        "  data_2020_apr_to_jun = data_2020_apr_to_jun.drop(columns = [\"dmcode\"])\n",
        "\n",
        "  data_2020_jan_to_mar = data_2020_jan_to_mar.loc[data_2020_jan_to_mar['District'] == district]\n",
        "  data_2020_jan_to_mar = data_2020_jan_to_mar.drop(columns=['Mandal'])\n",
        "  data_2020_jan_to_mar['Date'] = pd.to_datetime(data_2020_jan_to_mar['Date'],format='%Y/%m/%d')\n",
        "  data_2020_jan_to_mar = data_2020_jan_to_mar.groupby(['District', 'Date'], as_index=False).agg('max')\n",
        "  data_2020_jan_to_mar.index = data_2020_jan_to_mar['Date']\n",
        "  data_2020_jan_to_mar = data_2020_jan_to_mar.drop(columns=['Date'])\n",
        "  data_2020_jan_to_mar.columns = ['district', 'cumm_rainfall', 'temp_min', 'temp_max', 'humidity_min',\n",
        "        'humidity_max', 'wind_speed_max', 'wind_speed_min']\n",
        "  data_2020_jan_to_mar = data_2020_jan_to_mar.iloc[:,[0,1,2,3,4,5,7,6]]\n",
        "\n",
        "  data_2020_apr_to_jun = data_2020_apr_to_jun.loc[data_2020_apr_to_jun['district'] == district]\n",
        "  data_2020_apr_to_jun = data_2020_apr_to_jun.drop(columns=['mandal'])\n",
        "  data_2020_apr_to_jun['date'] = pd.to_datetime(data_2020_apr_to_jun['date'],format='%Y/%m/%d')\n",
        "  data_2020_apr_to_jun = data_2020_apr_to_jun.groupby(['district', 'date'], as_index=False).agg('max')\n",
        "  data_2020_apr_to_jun.index = data_2020_apr_to_jun['date']\n",
        "  data_2020_apr_to_jun = data_2020_apr_to_jun.drop(columns=['date'])\n",
        "  data_2020_apr_to_jun.columns = ['district', 'cumm_rainfall', 'temp_min', 'temp_max', 'humidity_min',\n",
        "        'humidity_max', 'wind_speed_max', 'wind_speed_min']\n",
        "  data_2020_apr_to_jun = data_2020_apr_to_jun.iloc[:,[0,1,2,3,4,5,7,6]]\n",
        "\n",
        "  data_2020_jul_to_sep = data_2020_jul_to_sep.loc[data_2020_jul_to_sep['district'] == district]\n",
        "  data_2020_jul_to_sep = data_2020_jul_to_sep.drop(columns=['mandal'])\n",
        "  data_2020_jul_to_sep['date'] = pd.to_datetime(data_2020_jul_to_sep['date'],format='%Y/%m/%d')\n",
        "  data_2020_jul_to_sep = data_2020_jul_to_sep.groupby(['district', 'date'], as_index=False).agg('max')\n",
        "  data_2020_jul_to_sep.index = data_2020_jul_to_sep['date']\n",
        "  data_2020_jul_to_sep = data_2020_jul_to_sep.drop(columns=['date'])\n",
        "  data_2020_jul_to_sep.columns = ['district', 'cumm_rainfall', 'temp_min', 'temp_max', 'humidity_min',\n",
        "        'humidity_max', 'wind_speed_max', 'wind_speed_min']\n",
        "  data_2020_jul_to_sep = data_2020_jul_to_sep.iloc[:,[0,1,2,3,4,5,7,6]]\n",
        "\n",
        "  data_2020_oct_to_dec = data_2020_oct_to_dec.loc[data_2020_oct_to_dec['District'] == district]\n",
        "  data_2020_oct_to_dec = data_2020_oct_to_dec.drop(columns=['Mandal'])\n",
        "  data_2020_oct_to_dec['Date'] = pd.to_datetime(data_2020_oct_to_dec['Date'],format='%d-%b-%y')\n",
        "  data_2020_oct_to_dec = data_2020_oct_to_dec.groupby(['District', 'Date'], as_index=False).agg('max')\n",
        "  data_2020_oct_to_dec.index = data_2020_oct_to_dec['Date']\n",
        "  data_2020_oct_to_dec = data_2020_oct_to_dec.drop(columns=['Date'])\n",
        "  data_2020_oct_to_dec.columns = data_2019_allwarangal.columns\n",
        "\n",
        "  data_2020_allwarangal = pd.concat([data_2020_jan_to_mar, data_2020_apr_to_jun, data_2020_jul_to_sep, data_2020_oct_to_dec])\n",
        "  #2020 Cleanup Ends------------------------------------------------------------------------------------------------\n",
        "\n",
        "  #2021 Cleanup Begins-----------------------------------------------------------------------------------------------\n",
        "  data_2021_jan_to_mar = pd.read_csv('raw_data/Weather_Jan_to_Mar_2021.xlsx - Wearther.csv')\n",
        "  data_2021_apr = pd.read_csv('raw_data/TS Weather Data April 2021 .csv') \n",
        "  data_2021_may = pd.read_csv('raw_data/TS Weather data May 2021.csv')\n",
        "  data_2021_june = pd.read_csv('raw_data/TS Weather data June 2021.csv')\n",
        "  data_2021_jul = pd.read_csv('raw_data/TS Weather data July 2021.csv')\n",
        "  data_2021_aug = pd.read_csv('raw_data/TS Weather data August 2021.csv') \n",
        "  data_2021_sep = pd.read_csv('raw_data/TS Weather data September 2021.csv')\n",
        "  data_2021_oct = pd.read_csv('raw_data/TS Weather data October 2021.csv')\n",
        "  data_2021_nov = pd.read_csv('raw_data/TS Weather data November 2021.csv')\n",
        "  data_2021_dec = pd.read_csv('raw_data/TS Weather data December 2021.csv')\n",
        "\n",
        "  l = [data_2021_jan_to_mar,data_2021_apr,data_2021_may,data_2021_june,data_2021_jul,data_2021_aug,data_2021_sep,data_2021_oct,data_2021_nov,data_2021_dec]\n",
        "  for i in range(0,10):\n",
        "    l[i] = l[i].loc[l[i]['District'] == 'Karimnagar']\n",
        "    l[i] = l[i].drop(columns=['Mandal'])\n",
        "    l[i]['Date'] = pd.to_datetime(l[i]['Date'],format='%d-%b-%y')\n",
        "    l[i] = l[i].groupby(['District', 'Date'], as_index=False).agg('max')\n",
        "    l[i].index = l[i]['Date']\n",
        "    l[i] = l[i].drop(columns=['Date'])\n",
        "    l[i].columns = data_2019_allwarangal.columns\n",
        "\n",
        "  data_2021_allwarangal = pd.concat(l)\n",
        "  #2021 Cleanup Ends------------------------------------------------------------------------------------------------\n",
        "\n",
        "  #2022 Cleanup Begins----------------------------------------------------------------------------------------------\n",
        "  data_2022_jan = pd.read_csv('raw_data/TS Weather data January 2022.csv')\n",
        "  data_2022_feb = pd.read_csv('raw_data/TS Weather data February 2022.csv') \n",
        "  data_2022_mar = pd.read_csv('raw_data/TS Weather data March 2022.csv')\n",
        "  data_2022_apr = pd.read_csv('raw_data/TS Weather data April 2022..csv')\n",
        "  data_2022_may = pd.read_csv('raw_data/TS Weather data May 2022_0.csv')\n",
        "  data_2022_jun = pd.read_csv('raw_data/TS Weather data June 2022_0.csv') \n",
        "  data_2022_jul = pd.read_csv('raw_data/TS Weather data July 2022_0.csv')\n",
        "  data_2022_aug = pd.read_csv('raw_data/TS Weather data August 2022.csv')\n",
        "  data_2022_sep = pd.read_csv('raw_data/TS Weather data September 2022.csv')\n",
        "\n",
        "  l = [data_2022_jan,data_2022_feb,data_2022_mar,data_2022_apr,data_2022_may,data_2022_jun,data_2022_jul,data_2022_aug,data_2022_sep]\n",
        "  for i in range(0,9):\n",
        "    l[i] = l[i].loc[l[i]['District'] == 'Karimnagar']\n",
        "    l[i] = l[i].drop(columns=['Mandal'])\n",
        "    l[i]['Date'] = pd.to_datetime(l[i]['Date'],format='%d-%b-%y')\n",
        "    l[i] = l[i].groupby(['District', 'Date'], as_index=False).agg('max')\n",
        "    l[i].index = l[i]['Date']\n",
        "    l[i] = l[i].drop(columns=['Date'])\n",
        "    l[i].columns = data_2019_allwarangal.columns\n",
        "  \n",
        "  data_2022_allwarangal = pd.concat(l)\n",
        "  #2022 Cleanup Ends------------------------------------------------------------------------------------------------\n",
        "\n",
        "  #Bring all the data into single dataframe-------------------------------------------------------------------------\n",
        "  warangal = pd.concat([data_2018_allwarangal,data_2019_allwarangal,data_2020_allwarangal,data_2021_allwarangal,data_2022_allwarangal])\n",
        "  plt.figure(figsize=(20,10))\n",
        "  plt.plot(warangal.index,warangal['temp_max']) #Plot the function to see if all things went smooth.\n",
        "\n",
        "  warangal.index.name = 'Date'\n",
        "  warangal.to_csv('cleaned_data/{}-cleaned.csv'.format(district), index=True) #Save the file in the format of {DISTRICT}-cleaned.csv"
      ],
      "metadata": {
        "id": "wOa7u4s75R6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problems with Warangal:\n",
        "1. daily weather cleanup function must be run for all the Warangal Districts namely:  \n",
        "  *   Warangal\n",
        "  *   Warangal (R)\n",
        "  *   Warangal (U)\n",
        "  *   Warangal Urban\n",
        "  *   Warangal Rural\n",
        "\n",
        "2. Following which we will receive 5 cleaned files which them needs to be merged. Call the warangal_merge function to do so by passing in all the cleaned files from the above step."
      ],
      "metadata": {
        "id": "j0fzxDhO8Fm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def warangal_merge():\n",
        "  '''\n",
        "  The function does not take any arguments. Instead, the function takes the 5 required files from the directory mentioned.\n",
        "  The function writes back the file to the appropriate directory.\n",
        "  Returns: None\n",
        "  '''\n",
        "  r = pd.read_csv('cleaned_data/Warangal (R)-cleaned.csv')\n",
        "  u = pd.read_csv('cleaned_data/Warangal (U)-cleaned.csv')\n",
        "  rural = pd.read_csv('cleaned_data/Warangal Rural-cleaned.csv')\n",
        "  urban = pd.read_csv('cleaned_data/Warangal Urban-cleaned.csv')\n",
        "  only = pd.read_csv('cleaned_data/Warangal-cleaned.csv')\n",
        "\n",
        "  r = r.dropna()\n",
        "  u = u.dropna()\n",
        "  rural = rural.dropna()\n",
        "  urban = urban.dropna()\n",
        "  only = only.dropna()\n",
        "\n",
        "  warangal = pd.concat([r,u,rural,urban,only])\n",
        "  warangal['District'] = 'Warangal'\n",
        "  warangal = warangal.rename(columns={  \n",
        "      'Unnamed: 0' : 'Date'\n",
        "  })\n",
        "  warangal = warangal.drop(columns='district')\n",
        "  warangal = warangal.groupby(['District', 'Date'], as_index=False).agg('cleaned')\n",
        "  warangal.index = warangal['Date']\n",
        "  warangal.drop(columns=['Date'],inplace=True)\n",
        "\n",
        "  warangal.to_csv('data/Warangal-cleaned.csv', index=True)"
      ],
      "metadata": {
        "id": "08f1Xy3l8EUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling the functions"
      ],
      "metadata": {
        "id": "g9N_gQ-qAc2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For the other districts\n",
        "daily_weather_cleanup('Adilabad')\n",
        "daily_weather_cleanup('Karimnagar')\n",
        "daily_weather_cleanup('Khammam')\n",
        "daily_weather_cleanup('Nizamabad')\n",
        "\n",
        "#For Warangal\n",
        "daily_weather_cleanup('Warangal')\n",
        "daily_weather_cleanup('Warangal (R)')\n",
        "daily_weather_cleanup('Warangal (U)')\n",
        "daily_weather_cleanup('Warangal Rural')\n",
        "daily_weather_cleanup('Warangal Urban')\n",
        "\n",
        "#Final merge of warangal\n",
        "warangal_merge()"
      ],
      "metadata": {
        "id": "gZr2342wABUg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}